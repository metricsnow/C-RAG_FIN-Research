# Contextual RAG-Powered Financial Research Assistant

A production-ready RAG (Retrieval-Augmented Generation) system for semantic search across financial documents, featuring flexible LLM deployment (Ollama or OpenAI) and comprehensive citation tracking.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![LangChain](https://img.shields.io/badge/LangChain-1.0+-green.svg)](https://python.langchain.com/)
[![Status](https://img.shields.io/badge/Status-MVP%20Complete-success.svg)](https://github.com/metricsnow/C-RAG_FIN-Research)

**Full documentation**: See [`project/README.md`](project/README.md) for comprehensive setup and usage instructions.

## Project Overview

This project demonstrates a production-ready RAG (Retrieval-Augmented Generation) system for financial research, implementing state-of-the-art techniques for semantic search across financial documents including SEC filings, research papers, market reports, and news articles.

The system serves as a hands-on demonstration of modern RAG architecture, exploring practical implementations of advanced techniques including hybrid search, query refinement, and multi-provider LLM integration. It provides a working example of how these components integrate in a production environment.

### System Components

The project is organized into several key modules, each implementing specific state-of-the-art techniques:

- **Document Ingestion Pipeline**: Implements intelligent chunking strategies, batch embedding generation, and metadata extraction for financial documents
- **RAG Chain**: Advanced retrieval with hybrid search (semantic + BM25), query expansion, reranking capabilities, and citation tracking
- **Vector Database Integration**: ChromaDB implementation with persistent storage, similarity search optimization, and metadata filtering (including sentiment-based filtering)
- **LLM Factory Pattern**: Dual-provider support (Ollama/OpenAI) with seamless switching, demonstrating provider abstraction patterns
- **Query Processing**: Query refinement, prompt engineering for financial domain, context-aware retrieval optimization, and sentiment-aware query filtering
- **Monitoring & Observability**: Prometheus metrics integration, health check endpoints, and comprehensive logging infrastructure

### State-of-the-Art Techniques Implemented

- **Hybrid Search**: Combines semantic similarity search with BM25 keyword matching for improved retrieval accuracy
- **Query Expansion**: Automatic query refinement and expansion to improve retrieval relevance
- **Reranking**: Cross-encoder reranking for optimal document ordering
- **Sentiment-Aware Filtering**: Filter query results by sentiment (positive/negative/neutral) for targeted document retrieval
- **Dual-Provider Architecture**: Flexible LLM and embedding provider switching without code changes
- **Financial Domain Optimization**: Custom prompt engineering and domain-specific embeddings for financial terminology
- **Production-Grade Architecture**: Type-safe configuration (Pydantic), comprehensive testing (82.75% coverage), and monitoring integration

## Technology Stack

### Core Technologies
- **Python 3.11+**: Modern Python with type hints, pattern matching, and performance optimizations
- **LangChain 1.0+**: RAG framework using Expression Language (LCEL) for declarative chain composition and streaming support
- **ChromaDB**: Vector database with persistent storage, metadata filtering (including sentiment-based filtering), and optimized similarity search
- **Streamlit**: Interactive web frontend with real-time streaming and state management

### LLM & Embeddings Architecture
- **Ollama**: Local LLM deployment (Llama 3.2) enabling privacy-preserving inference
- **OpenAI API**: Cloud-based embeddings (text-embedding-3-small) and LLM (gpt-4o-mini) support
- **Factory Pattern**: Provider abstraction layer enabling seamless switching between LLM and embedding providers
- **Multi-Provider Support**: Unified interface supporting multiple providers with runtime switching

### Advanced RAG Components
- **Hybrid Search**: Semantic vector search combined with BM25 keyword matching
- **Query Refinement**: Automatic query expansion and refinement techniques
- **Reranking**: Cross-encoder reranking for optimal document ordering
- **Sentiment-Aware Filtering**: Filter query results by document sentiment for targeted retrieval
- **Intelligent Chunking**: Recursive character text splitting with overlap strategies and metadata preservation

### Data Sources & Integration
- **SEC EDGAR API**: Automated document fetching pipeline for SEC filings (10-K, 10-Q, 8-K)
- **Stock Data Integration**: Comprehensive stock market data via yfinance (company info, financial metrics, historical prices, dividends, earnings, analyst recommendations)
- **Earnings Call Transcripts**: Fetch and index earnings call transcripts with speaker annotation, Q&A sections, and forward guidance extraction
- **Financial News Aggregation**: RSS feeds and web scraping for financial news from Reuters, CNBC, Bloomberg with ticker detection and categorization
- **Economic Calendar Integration**: Macroeconomic indicators and events via Trading Economics API
- **FRED API Integration**: 840,000+ economic time series including interest rates, exchange rates, inflation, employment, GDP
- **IMF and World Bank Data Integration**: Global economic data from IMF Data Portal and World Bank Open Data APIs for 188+ countries
- **Central Bank Data Integration**: FOMC statements, meeting minutes, press conference transcripts, and forward guidance extraction
- **Financial Sentiment Analysis**: Comprehensive sentiment analysis using FinBERT, TextBlob, and VADER with forward guidance and risk factor extraction, plus sentiment-aware query filtering
- **Document Processing**: Multi-format support (text, Markdown) with intelligent chunking and metadata extraction
- **Batch Processing**: Optimized batch embedding generation for efficient document indexing

### Development & Quality Infrastructure
- **Pydantic**: Type-safe configuration management with runtime validation
- **pytest**: Comprehensive test suite with 174 tests achieving 82.75% coverage
- **mypy**: Static type checking for enhanced code quality and maintainability
- **Pre-commit Hooks**: Automated code formatting (black, isort) and linting (flake8)
- **Prometheus**: Metrics collection and monitoring for observability
- **Sphinx**: API documentation generation with automated docstring processing

## System Process Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DOCUMENT INGESTION FLOW                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Documents   â”‚
    â”‚ (Text/MD/    â”‚
    â”‚  SEC EDGAR)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Document Loader â”‚  Extract text, validate size, extract metadata
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Text Chunking  â”‚  RecursiveCharacterTextSplitter (800 chars, 150 overlap)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Embedding Gen    â”‚  OpenAI text-embedding-3-small or Ollama embeddings
    â”‚ (Batch Process)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   ChromaDB       â”‚  Store chunks + embeddings + metadata
    â”‚  Vector Store    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           QUERY PROCESSING FLOW                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ User Query   â”‚  Natural language question
    â”‚ (Streamlit)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Query Embedding â”‚  Convert query to vector representation
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Vector Search    â”‚  Similarity search in ChromaDB (top-k retrieval)
    â”‚ (ChromaDB)       â”‚  Optional: Hybrid search (semantic + BM25)
    â”‚                  â”‚  Optional: Sentiment filtering (positive/negative/neutral)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Context Retrievalâ”‚  Retrieve top-k relevant document chunks
    â”‚ (Top-K Chunks)   â”‚  Optional: Reranking with cross-encoder
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Prompt Building  â”‚  Format context + query with financial domain prompts
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ LLM Generation   â”‚  Ollama (local) or OpenAI (cloud) inference
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Answer +         â”‚  Generated answer with source citations
    â”‚ Citations        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Features

### Core Capabilities
- **Semantic Document Search**: Natural language queries across financial documents using vector similarity search
- **Multi-Provider LLM Architecture**: Factory pattern implementation supporting Ollama (local) and OpenAI (cloud) providers
- **Citation Tracking**: Automatic source attribution with document references and metadata for traceability
- **SEC EDGAR Integration**: Automated document fetching and indexing pipeline for SEC filings (10-K, 10-Q, 8-K forms)
- **Financial Domain Optimization**: Domain-specific prompt engineering and embedding strategies for financial terminology
- **FastAPI Backend**: Production-ready RESTful API with OpenAPI documentation, authentication, and rate limiting
- **Document Management**: Comprehensive UI for managing indexed documents with search, filtering, and deletion
- **Conversation Memory**: Multi-turn conversations with context preservation and LangChain memory integration
- **Financial Sentiment Analysis**: Automatic sentiment analysis for all documents using FinBERT, TextBlob, and VADER with sentiment-aware query filtering

### Advanced RAG Techniques
- **Hybrid Search**: Combines semantic vector search with BM25 keyword matching for improved retrieval precision
- **Query Refinement**: Automatic query expansion and refinement to enhance retrieval relevance
- **Reranking**: Cross-encoder reranking implementation for optimal document ordering
- **Sentiment-Aware Filtering**: Filter query results by document sentiment (positive/negative/neutral) for targeted retrieval
- **Dual Embedding Support**: OpenAI (text-embedding-3-small) or Ollama embeddings with provider abstraction
- **Intelligent Chunking**: Recursive character text splitting with overlap strategies for optimal context preservation

### Infrastructure & Architecture
- **Vector Database**: ChromaDB with persistent storage, metadata filtering (including sentiment-based filtering), and similarity search optimization
- **Streamlit UI**: Interactive chat interface with real-time model switching and query processing
- **FastAPI Backend**: RESTful API with OpenAPI/Swagger documentation, authentication, and rate limiting
- **Performance Metrics**: Average query response time 3.46s with comprehensive performance monitoring
- **Observability**: Prometheus metrics integration, health check endpoints, and structured logging
- **Code Quality**: Pre-commit hooks (black, isort, flake8), static type checking (mypy), and comprehensive test coverage

## Performance Metrics

- **Query Response Time**: 3.46s average (target: <5s) âœ…
- **Documents Indexed**: 50 documents, 511 chunks
- **Test Coverage**: **82.75%** (174 tests) âœ… - Exceeded 80% target
- **Code Quality**: Pre-commit hooks, mypy type checking, comprehensive logging âœ…
- **Monitoring**: Prometheus metrics and health check endpoints âœ…
- **System Status**: Production-ready MVP + Post-MVP enhancements complete âœ…

## Repository Structure

```
.
â”œâ”€â”€ project/                    # Main application code
â”‚   â”œâ”€â”€ app/                    # Application source code
â”‚   â”‚   â”œâ”€â”€ api/                # FastAPI backend
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py              # Authentication middleware
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI application entry point
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware.py        # Request middleware
â”‚   â”‚   â”‚   â”œâ”€â”€ models/              # API data models
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ documents.py     # Document models
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py     # Ingestion models
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ query.py         # Query models
â”‚   â”‚   â”‚   â””â”€â”€ routes/              # API route handlers
â”‚   â”‚   â”‚       â”œâ”€â”€ documents.py     # Document endpoints
â”‚   â”‚   â”‚       â”œâ”€â”€ health.py        # Health check endpoints
â”‚   â”‚   â”‚       â”œâ”€â”€ ingestion.py     # Ingestion endpoints
â”‚   â”‚   â”‚       â””â”€â”€ query.py         # Query endpoints
â”‚   â”‚   â”œâ”€â”€ ingestion/          # Document ingestion pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ document_loader.py    # Multi-format document loading
â”‚   â”‚   â”‚   â”œâ”€â”€ edgar_fetcher.py      # SEC EDGAR API integration
â”‚   â”‚   â”‚   â”œâ”€â”€ yfinance_fetcher.py   # Stock data integration
â”‚   â”‚   â”‚   â”œâ”€â”€ transcript_fetcher.py  # Earnings call transcripts
â”‚   â”‚   â”‚   â”œâ”€â”€ news_fetcher.py        # Financial news aggregation
â”‚   â”‚   â”‚   â”œâ”€â”€ economic_calendar_fetcher.py # Economic calendar
â”‚   â”‚   â”‚   â”œâ”€â”€ fred_fetcher.py       # FRED API integration
â”‚   â”‚   â”‚   â”œâ”€â”€ imf_fetcher.py        # IMF Data Portal integration
â”‚   â”‚   â”‚   â”œâ”€â”€ world_bank_fetcher.py  # World Bank API integration
â”‚   â”‚   â”‚   â”œâ”€â”€ central_bank_fetcher.py # Central bank data
â”‚   â”‚   â”‚   â”œâ”€â”€ sentiment_analyzer.py # Financial sentiment analysis
â”‚   â”‚   â”‚   â””â”€â”€ pipeline.py           # End-to-end ingestion orchestration
â”‚   â”‚   â”œâ”€â”€ rag/                # RAG chain implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ chain.py              # LCEL-based RAG chain with streaming
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_factory.py        # Multi-provider LLM abstraction
â”‚   â”‚   â”‚   â”œâ”€â”€ embedding_factory.py  # Multi-provider embedding abstraction
â”‚   â”‚   â”‚   â”œâ”€â”€ prompt_engineering.py # Financial domain prompts
â”‚   â”‚   â”‚   â”œâ”€â”€ query_refinement.py   # Query expansion and refinement
â”‚   â”‚   â”‚   â””â”€â”€ retrieval_optimizer.py # Hybrid search and reranking
â”‚   â”‚   â”œâ”€â”€ ui/                 # Streamlit frontend
â”‚   â”‚   â”‚   â”œâ”€â”€ app.py                # Interactive chat interface
â”‚   â”‚   â”‚   â””â”€â”€ document_management.py # Document management UI
â”‚   â”‚   â”œâ”€â”€ utils/              # Configuration and utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py            # Pydantic-based configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation_export.py # Conversation export utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation_memory.py # Conversation state management
â”‚   â”‚   â”‚   â”œâ”€â”€ document_manager.py   # Document management utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ health.py            # Health check utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ logger.py            # Structured logging
â”‚   â”‚   â”‚   â””â”€â”€ metrics.py           # Prometheus metrics
â”‚   â”‚   â””â”€â”€ vector_db/          # ChromaDB integration
â”‚   â”‚       â””â”€â”€ chroma_store.py      # Vector store operations
â”‚   â”œâ”€â”€ docs/                   # Documentation
â”‚   â”‚   â”œâ”€â”€ api.md              # API documentation
â”‚   â”‚   â”œâ”€â”€ configuration.md   # Configuration guide
â”‚   â”‚   â”œâ”€â”€ deployment.md       # Deployment guide
â”‚   â”‚   â”œâ”€â”€ edgar_integration.md # SEC EDGAR integration docs
â”‚   â”‚   â”œâ”€â”€ prd-phase1.md       # Phase 1 Product Requirements
â”‚   â”‚   â”œâ”€â”€ prd-phase2.md       # Phase 2 Planning Document
â”‚   â”‚   â”œâ”€â”€ testing.md          # Testing documentation
â”‚   â”‚   â””â”€â”€ sphinx/             # Sphinx documentation build
â”‚   â”œâ”€â”€ dev/                    # Development tasks and bugs
â”‚   â”‚   â”œâ”€â”€ archive/            # Completed tasks and bugs
â”‚   â”‚   â”‚   â”œâ”€â”€ bugs_done/      # Completed bug reports
â”‚   â”‚   â”‚   â””â”€â”€ tasks_done/     # Completed tasks
â”‚   â”‚   â”œâ”€â”€ bugs/               # Active bug reports
â”‚   â”‚   â””â”€â”€ tasks/              # Active tasks
â”‚   â”œâ”€â”€ scripts/                # Utility scripts
â”‚   â”‚   â”œâ”€â”€ deploy_local.sh          # Local deployment script
â”‚   â”‚   â”œâ”€â”€ deploy_with_ngrok.sh     # ngrok deployment script
â”‚   â”‚   â”œâ”€â”€ example_chromadb_usage.py # ChromaDB usage examples
â”‚   â”‚   â”œâ”€â”€ fetch_edgar_data.py       # SEC data fetching utilities
â”‚   â”‚   â”œâ”€â”€ fetch_stock_data.py       # Stock data fetching
â”‚   â”‚   â”œâ”€â”€ fetch_transcripts.py     # Earnings call transcripts
â”‚   â”‚   â”œâ”€â”€ fetch_news.py             # News aggregation
â”‚   â”‚   â”œâ”€â”€ fetch_economic_calendar.py # Economic calendar
â”‚   â”‚   â”œâ”€â”€ fetch_fred_data.py        # FRED API data
â”‚   â”‚   â”œâ”€â”€ fetch_imf_data.py         # IMF data
â”‚   â”‚   â”œâ”€â”€ fetch_world_bank_data.py  # World Bank data
â”‚   â”‚   â”œâ”€â”€ fetch_central_bank_data.py # Central bank data
â”‚   â”‚   â”œâ”€â”€ run_streamlit.py         # Streamlit application launcher
â”‚   â”‚   â”œâ”€â”€ start_api.py              # API server launcher
â”‚   â”‚   â”œâ”€â”€ start_streamlit.sh       # Streamlit startup script
â”‚   â”‚   â”œâ”€â”€ validate_chromadb_comprehensive.py # Comprehensive DB validation
â”‚   â”‚   â”œâ”€â”€ validate_chromadb_data.py # Database data validation
â”‚   â”‚   â”œâ”€â”€ validate_setup.py        # Setup validation
â”‚   â”‚   â””â”€â”€ verify_document_indexing.py # Document indexing verification
â”‚   â”œâ”€â”€ tests/                  # Comprehensive test suite
â”‚   â”‚   â”œâ”€â”€ test_rag_chain_comprehensive.py  # RAG chain tests
â”‚   â”‚   â”œâ”€â”€ test_chromadb_comprehensive.py   # Vector DB tests
â”‚   â”‚   â”œâ”€â”€ test_pipeline_comprehensive.py   # Ingestion tests
â”‚   â”‚   â””â”€â”€ test_end_to_end.py               # Integration tests
â”‚   â”œâ”€â”€ pyproject.toml          # Project configuration and dependencies
â”‚   â”œâ”€â”€ pytest.ini              # pytest configuration
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ streamlit_app.py        # Streamlit application entry point
â”‚   â”œâ”€â”€ START_STREAMLIT.sh      # Streamlit startup script
â”‚   â””â”€â”€ README.md               # Detailed project README
```

## Documentation

- **[Project README](project/README.md)**: Comprehensive setup, usage, and architecture guide
- **[API Documentation](project/docs/api.md)**: FastAPI endpoints and usage
- **[Configuration Guide](project/docs/reference/configuration.md)**: Configuration options and environment variables
- **[Phase 1 PRD](project/docs/prd-phase1.md)**: Complete Phase 1 MVP requirements and specifications
- **[Phase 2 PRD](project/docs/prd-phase2.md)**: Phase 2 enhancement planning
- **[Deployment Guide](project/docs/reference/deployment.md)**: Deployment instructions for local, ngrok, and VPS
- **[Integration Guides](project/docs/integrations/)**: Comprehensive integration documentation
  - [Sentiment Analysis](project/docs/integrations/sentiment_analysis.md)
  - [News Aggregation](project/docs/integrations/news_aggregation.md)
  - [Stock Data](project/docs/integrations/yfinance_integration.md)
  - [FRED API](project/docs/integrations/fred_integration.md)
  - [IMF & World Bank](project/docs/integrations/imf_world_bank_integration.md)
  - [Central Bank Data](project/docs/integrations/central_bank_integration.md)
- **[Testing Documentation](project/docs/testing.md)**: Testing guidelines and test suite information

## Deployment Options

1. **Local Deployment**: Development and testing
2. **ngrok Tunnel**: External access for demos
3. **VPS Deployment**: Production deployment (see [deployment guide](project/docs/deployment.md))

**Note**: Ollama requires self-hosting, so Streamlit Cloud is not an option.

## Development Roadmap

### Completed (Phase 1 - MVP)
- âœ… All 13 core tasks completed
- âœ… MVP fully functional
- âœ… Comprehensive documentation

### Completed (Post-MVP Enhancements)
- âœ… All 10 post-MVP enhancement tasks completed
- âœ… Code quality infrastructure (pre-commit, mypy, type checking)
- âœ… Test coverage enhanced to 82.75% (174 tests)
- âœ… Monitoring and observability (Prometheus metrics, health checks)
- âœ… Comprehensive logging infrastructure
- âœ… Pydantic-based configuration management
- âœ… Modern dependency management (pyproject.toml)
- âœ… API documentation generation (Sphinx)
- âœ… Conversation memory context usage

### Completed (Phase 2)
- âœ… FastAPI backend with OpenAPI documentation, authentication, and rate limiting
- âœ… Enhanced data sources (yfinance, FRED, IMF, World Bank, Economic Calendar)
- âœ… Advanced analytics (sentiment analysis with FinBERT/TextBlob/VADER, forward guidance extraction, risk factor identification, sentiment-aware query filtering)
- âœ… Conversation history management UI (clear/export features)
- âœ… Earnings call transcripts integration
- âœ… Financial news aggregation with RSS feeds and web scraping
- âœ… Central bank data integration (FOMC statements, minutes, press conferences)
- âœ… Document management UI with search, filtering, and deletion
- âœ… RAG optimization (hybrid search, reranking, query refinement)

### Planned (Future Enhancements)
- âœ… News article summarization
- âœ… News trend analysis
- âœ… Automated news monitoring
- ğŸ“‹ News alert system
- ğŸ“‹ Additional performance optimizations

See [Phase 2 PRD](project/docs/prd-phase2.md) for detailed planning.

## Acknowledgments

- **LangChain**: RAG framework and chain orchestration
- **Ollama**: Local LLM deployment
- **ChromaDB**: Vector database
- **Streamlit**: Web frontend framework
- **SEC EDGAR**: Financial document data source

## Technical Development

This project utilizes a self-developed Cursor AI framework to optimize coding speed and maintainability. The framework provides specialized AI personas (Mission Analyst, Mission Planner, Mission Executor, Mission-QA, Mission Challenger, etc.) through slash commands, enabling sequential persona switching and orchestrated multi-agent workflows for complex technical tasks. The framework uses BPMN workflows, quality gates, and state persistence to ensure consistent code quality, comprehensive testing, and efficient project progress while maintaining complete autonomy from the project codebase.
